{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, RandomForestRegressor,\n",
    "    GradientBoostingRegressor, VotingClassifier, StackingRegressor\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 1. Load and Copy Data\n",
    "# ---------------------------------------------\n",
    "df = pd.read_csv('gwas_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------\n",
    "# 2. Define Columns\n",
    "# ---------------------------------------------\n",
    "input_cols = ['SNPS', 'LOCATION', 'RISK_ALLELE', 'MAPPED_GENE', 'RISK ALLELE FREQUENCY']\n",
    "target_class = 'DISEASE/TRAIT'\n",
    "target_reg1 = 'OR or BETA'\n",
    "target_reg2 = 'polygenic_score'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 3. Filter Out Rare Classes (< 3 samples)\n",
    "# ---------------------------------------------\n",
    "class_counts = df[target_class].value_counts()\n",
    "valid_classes = class_counts[class_counts > 2].index\n",
    "df = df[df[target_class].isin(valid_classes)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 4. Label Encoding\n",
    "# ---------------------------------------------\n",
    "label_encoders = {}\n",
    "for col in ['SNPS', 'LOCATION', 'RISK_ALLELE', 'MAPPED_GENE']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode Target Class\n",
    "le_target = LabelEncoder()\n",
    "df[target_class] = le_target.fit_transform(df[target_class].astype(str))\n",
    "label_encoders['DISEASE/TRAIT'] = le_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 5. Define X and y\n",
    "# ---------------------------------------------\n",
    "X = df[input_cols]\n",
    "y_class = df[target_class]\n",
    "y_reg1 = df[target_reg1]\n",
    "y_reg2 = df[target_reg2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 6. Stratified Train-Test Split\n",
    "# ---------------------------------------------\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_idx, test_idx in sss.split(X, y_class):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_class_train, y_class_test = y_class.iloc[train_idx], y_class.iloc[test_idx]\n",
    "    y_reg1_train, y_reg1_test = y_reg1.iloc[train_idx], y_reg1.iloc[test_idx]\n",
    "    y_reg2_train, y_reg2_test = y_reg2.iloc[train_idx], y_reg2.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Classification Models:\n",
      "RF Accuracy: 0.7596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkateshp/miniconda3/envs/ven/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [09:39:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Accuracy: 0.7760\n",
      "LOGREG Accuracy: 0.7322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkateshp/miniconda3/envs/ven/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/venkateshp/miniconda3/envs/ven/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [09:39:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier Accuracy: 0.7650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkateshp/miniconda3/envs/ven/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['voting_classifier.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 7. Classification Models\n",
    "# ---------------------------------------------\n",
    "print(\"\\nðŸŽ¯ Classification Models:\")\n",
    "\n",
    "models_class = {\n",
    "    \"rf\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"xgb\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"logreg\": LogisticRegression(max_iter=500),\n",
    "}\n",
    "\n",
    "for name, model in models_class.items():\n",
    "    model.fit(X_train, y_class_train)\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_class_test, pred)\n",
    "    print(f\"{name.upper()} Accuracy: {acc:.4f}\")\n",
    "    joblib.dump(model, f\"{name}_classifier.pkl\")\n",
    "\n",
    "# Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(name, model) for name, model in models_class.items()],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train, y_class_train)\n",
    "voting_acc = accuracy_score(y_class_test, voting_clf.predict(X_test))\n",
    "print(f\"VotingClassifier Accuracy: {voting_acc:.4f}\")\n",
    "joblib.dump(voting_clf, \"voting_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Regression Models (OR or BETA):\n",
      "RF MSE (OR or BETA): 0.0047\n",
      "XGB MSE (OR or BETA): 0.0052\n",
      "LINREG MSE (OR or BETA): 0.0059\n",
      "GBR MSE (OR or BETA): 0.0048\n",
      "StackingRegressor MSE (OR or BETA): 0.0046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stacking_or_beta.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 8. Regression Models (OR or BETA)\n",
    "# ---------------------------------------------\n",
    "print(\"\\nðŸ“ˆ Regression Models (OR or BETA):\")\n",
    "\n",
    "models_reg = {\n",
    "    \"rf\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"xgb\": XGBRegressor(random_state=42),\n",
    "    \"linreg\": LinearRegression(),\n",
    "    \"gbr\": GradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "for name, model in models_reg.items():\n",
    "    model.fit(X_train, y_reg1_train)\n",
    "    pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_reg1_test, pred)\n",
    "    print(f\"{name.upper()} MSE (OR or BETA): {mse:.4f}\")\n",
    "    joblib.dump(model, f\"{name}_or_beta.pkl\")\n",
    "\n",
    "# Stacking Regressor (OR or BETA)\n",
    "stack_reg1 = StackingRegressor(\n",
    "    estimators=[(name, model) for name, model in models_reg.items()],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "stack_reg1.fit(X_train, y_reg1_train)\n",
    "stack_pred1 = stack_reg1.predict(X_test)\n",
    "mse_stack1 = mean_squared_error(y_reg1_test, stack_pred1)\n",
    "print(f\"StackingRegressor MSE (OR or BETA): {mse_stack1:.4f}\")\n",
    "joblib.dump(stack_reg1, \"stacking_or_beta.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Regression Models (Polygenic Score):\n",
      "RF MSE (Polygenic Score): 34.3853\n",
      "XGB MSE (Polygenic Score): 28.9873\n",
      "LINREG MSE (Polygenic Score): 39.2213\n",
      "GBR MSE (Polygenic Score): 27.1424\n",
      "StackingRegressor MSE (Polygenic Score): 34.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stacking_polygenic.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 9. Regression Models (Polygenic Score)\n",
    "# ---------------------------------------------\n",
    "print(\"\\nðŸ“ˆ Regression Models (Polygenic Score):\")\n",
    "\n",
    "for name, model in models_reg.items():\n",
    "    model.fit(X_train, y_reg2_train)\n",
    "    pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_reg2_test, pred)\n",
    "    print(f\"{name.upper()} MSE (Polygenic Score): {mse:.4f}\")\n",
    "    joblib.dump(model, f\"{name}_polygenic.pkl\")\n",
    "\n",
    "# Stacking Regressor (Polygenic Score)\n",
    "stack_reg2 = StackingRegressor(\n",
    "    estimators=[(name, model) for name, model in models_reg.items()],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "stack_reg2.fit(X_train, y_reg2_train)\n",
    "stack_pred2 = stack_reg2.predict(X_test)\n",
    "mse_stack2 = mean_squared_error(y_reg2_test, stack_pred2)\n",
    "print(f\"StackingRegressor MSE (Polygenic Score): {mse_stack2:.4f}\")\n",
    "joblib.dump(stack_reg2, \"stacking_polygenic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All models and encoders saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 10. Save Encoders\n",
    "# ---------------------------------------------\n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "\n",
    "print(\"\\nâœ… All models and encoders saved successfully.\")\n",
    "# ---------------------------------------------\n",
    "# End of Script\n",
    "# ---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š FINAL MODEL PERFORMANCE SUMMARY\n",
      "----------------------------------------\n",
      "ðŸŽ¯ Classification Accuracies:\n",
      "RF        : 0.7596\n",
      "XGB       : 0.7760\n",
      "LOGREG    : 0.7322\n",
      "VOTING    : 0.7650\n",
      "\n",
      "ðŸ“ˆ Regression MSE (OR or BETA):\n",
      "RF        : 10.0725\n",
      "XGB       : 6.0702\n",
      "LINREG    : 2.6098\n",
      "GBR       : 7.1612\n",
      "STACKING  : 0.0046\n",
      "\n",
      "ðŸ“ˆ Regression MSE (Polygenic Score):\n",
      "RF        : 34.3853\n",
      "XGB       : 28.9873\n",
      "LINREG    : 39.2213\n",
      "GBR       : 27.1424\n",
      "STACKING  : 34.9880\n",
      "\n",
      "âœ… Training Complete. Models and scores ready.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 11. Final Summary of All Scores\n",
    "# ---------------------------------------------\n",
    "print(\"\\nðŸ“Š FINAL MODEL PERFORMANCE SUMMARY\\n\" + \"-\"*40)\n",
    "\n",
    "print(\"ðŸŽ¯ Classification Accuracies:\")\n",
    "for name, model in models_class.items():\n",
    "    acc = accuracy_score(y_class_test, model.predict(X_test))\n",
    "    print(f\"{name.upper():<10}: {acc:.4f}\")\n",
    "voting_acc = accuracy_score(y_class_test, voting_clf.predict(X_test))\n",
    "print(f\"{'VOTING':<10}: {voting_acc:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Regression MSE (OR or BETA):\")\n",
    "for name, model in models_reg.items():\n",
    "    mse = mean_squared_error(y_reg1_test, model.predict(X_test))\n",
    "    print(f\"{name.upper():<10}: {mse:.4f}\")\n",
    "print(f\"{'STACKING':<10}: {mse_stack1:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Regression MSE (Polygenic Score):\")\n",
    "for name, model in models_reg.items():\n",
    "    mse = mean_squared_error(y_reg2_test, model.predict(X_test))\n",
    "    print(f\"{name.upper():<10}: {mse:.4f}\")\n",
    "print(f\"{'STACKING':<10}: {mse_stack2:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Training Complete. Models and scores ready.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
